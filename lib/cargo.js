// Generated by CoffeeScript 2.5.1
(function() {
  var CLUSTER_WORKER_ID, Cargo, DEFAULT_COMMIT_INTERVAL, EXTNAME_UNCOMMITTED, FILENAME_PREFIX, MAX_COMMIT_PER_EXAM_ROUTINE, MIN_ROWS, MIN_TIME, NOOP, StaticCountWithinProcess, assert, cluster, crypto, debuglog, fs, fsAsync, isThisLeader, os, path, pipeline;

  fs = require("fs");

  //fs = require('fs/promises')
  fsAsync = require('fs/promises');

  os = require("os");

  path = require("path");

  crypto = require('crypto');

  cluster = require('cluster');

  ({pipeline} = require('stream'));

  assert = require("assert");

  //CombinedStream = require('combined-stream')
  ({pipeline} = require('stream/promises'));

  ({isThisLeader} = require("./leader_election"));

  CLUSTER_WORKER_ID = cluster.isMaster ? "nocluster" : cluster.worker.id;

  debuglog = require("debug")(`chcargo:cargo@${CLUSTER_WORKER_ID}`);

  require('stream/promises');

  FILENAME_PREFIX = "cargo_";

  EXTNAME_UNCOMMITTED = ".uncommitted";

  NOOP = function() {};

  MAX_COMMIT_PER_EXAM_ROUTINE = 1;

  MIN_TIME = 1000;

  MIN_ROWS = 100;

  DEFAULT_COMMIT_INTERVAL = 5000;

  StaticCountWithinProcess = 0;

  Cargo = class Cargo {
    toString() {
      return `[Cargo ${this.id}]`;
    }

    // @param ClickHouse clichouseClient
    // @param SQLInsertString statement
    // @param Object options:
    //                     .pathToCargoFolder
    //                     .maxTime
    //                     .maxRows
    //                     .commitInterval
    constructor(clichouseClient, statement, options = {}) {
      this.clichouseClient = clichouseClient;
      this.statement = statement;
      this.maxTime = parseInt(options.maxTime) || MIN_TIME;
      if (this.maxTime < MIN_TIME) {
        this.maxTime = MIN_TIME;
      }
      this.maxRows = parseInt(options.maxRows) || MIN_ROWS;
      if (this.maxRows < 1) {
        this.maxRows = MIN_ROWS;
      }
      this.commitInterval = parseInt(options.commitInterval) || DEFAULT_COMMIT_INTERVAL;
      if (this.commitInterval < this.maxTime) {
        this.commitInterval = DEFAULT_COMMIT_INTERVAL;
      }
      this.id = crypto.createHash('md5').update(this.statement).digest("hex");
      this.count = 0;
      this.bulks = [];
      assert(options.pathToCargoFolder, "missing options.pathToCargoFolder");
      this.pathToCargoFolder = options.pathToCargoFolder;
      this.pathToCargoFile = path.join(this.pathToCargoFolder, FILENAME_PREFIX + this.id);
      debuglog(`[new Cargo] @statement:${this.statement}, @maxTime:${this.maxTime}, @maxRows:${this.maxRows}, @commitInterval:${this.commitInterval}, @pathToCargoFile:${this.pathToCargoFile}`);
      // verify cargo can write to the destination folder
      fs.access(this.pathToCargoFolder, fs.constants.W_OK, function(err) {
        if (err != null) {
          throw new Error(`Cargo not able to write to folder ${this.pathToCargoFolder}. Due to ${err}`);
        }
      });
      this.cachedRows = [];
      this.lastFlushAt = Date.now();
      this.lastCommitAt = Date.now();
      return;
    }

    // push row insert into memory cache
    push() {
      var arr, i, item, j, len;
      arr = Array.from(arguments);
      assert(arr.length > 0, "blank row can not be accepted.");
      for (i = j = 0, len = arr.length; j < len; i = ++j) {
        item = arr[i];
        if (item instanceof Date) {
          arr[i] = Math.round(item.getDate() / 1000);
        }
      }
      this.cachedRows.push(JSON.stringify(arr));
      if ((this.cachedRows.length > this.maxRows) || (Date.now() > this.lastFlushAt + this.maxRows)) {
        //debuglog "[push] row? #{(@cachedRows.length > @maxRows)}, time? #{(Date.now() > @lastFlushAt + @maxRows)} "
        this.flushToFile();
      }
    }

    // flush memory cache to the disk file
    async flushToFile() {
      var err, rowsToFlush;
      //debuglog("#{@} [flushToFile] @_isFlushing:", @_isFlushing)
      if (this._isFlushing) {
        return;
      }
      if (!(this.cachedRows.length > 0)) {
        //debuglog("#{@} [flushToFile] nothing to flush")
        this.lastFlushAt = Date.now();
        return;
      }
      rowsToFlush = this.cachedRows;
      this.cachedRows = [];
      debuglog(`${this} [flushToFile] -> ${rowsToFlush.length} rows`);
      this._isFlushing = true;
      try {
        await fsAsync.appendFile(this.pathToCargoFile, rowsToFlush.join("\n") + "\n")((err) => {});
      } catch (error) {
        err = error;
        debuglog(`${this} [flushToFile] FAILED error:`, err);
        this.cachedRows = rowsToFlush.concat(this.cachedRows); // unshift data back
      }
      debuglog(`${this} [flushToFile] SUCCESS ${rowsToFlush.length} rows`);
      this.lastFlushAt = Date.now();
      this._isFlushing = false;
    }

    flushSync() {
      var rowsToFlush;
      if (!(this.cachedRows.length > 0)) {
        debuglog(`${this} [flushSync] nothing to flush`);
        return;
      }
      rowsToFlush = this.cachedRows;
      this.cachedRows = [];
      debuglog(`${this} [flushSync] ${rowsToFlush.length} rows`);
      fs.appendFileSync(this.pathToCargoFile, rowsToFlush.join("\n") + "\n");
    }

    // check if to commit disk file to clickhouse DB
    async exam() {
      var err;
      if (this._isExaming) {
        debuglog("[exam] SKIP @_isExaming");
        return;
      }
      this._isExaming = true; // lock on
      try {
        await this.flushToFile();
      } catch (error) {
        err = error;
        debuglog("[exam] ABORT fail to flush. error:", err);
        this._isExaming = false; // release
        return;
      }
      if (!(Date.now() > this.lastCommitAt + this.commitInterval)) {
        //debuglog "[exam] SKIP tick not reach"
        this._isExaming = false; // release
        return;
      }
      if (!isThisLeader()) {
        debuglog("[exam] CANCLE NOT leadWorkerId");
        // non-leader skip 10 commit rounds
        this.lastCommitAt = Date.now() + this.commitInterval * 10;
        this._isExaming = false; // release
        return;
      }
      debuglog("[exam] LEAD COMMIT");
      try {
        await this.rotateFile();
        await this.commitToClickhouseDB();
        this.lastCommitAt = Date.now();
      } catch (error) {
        err = error;
        debuglog("[exam] FAILED to commit. error:", err);
      }
      this._isExaming = false; // release
    }

    // prepar all uncommitted local files
    // @return Boolean, true if there are local uncommits exist
    async rotateFile() {
      var err, pathToRenameFile, stats;
      if (this._isFileRotating) {
        debuglog("[rotateFile] SKIP @_isFileRotating");
        return false;
      }
      this._isFileRotating = true; // lock on
      try {
        stats = (await fsAsync.stat(this.pathToCargoFile));
      } catch (error) {
        err = error;
        if (err.code === 'ENOENT') {
          debuglog("[rotateFile] SKIP nothing to rotate");
        } else {
          debuglog("[rotateFile] ABORT fail to stats file. error:", err);
        }
        this._isFileRotating = false; // lock released
        return false;
      }
      //debuglog "[rotateFile > stat] err:", err,", stats:", stats
      if (!(stats && (stats.size > 0))) {
        debuglog("[rotateFile] SKIP empty file.");
        this._isFileRotating = false; // lock released
        return false;
      }
      // rotate disk file
      pathToRenameFile = path.join(this.pathToCargoFolder, `${FILENAME_PREFIX}${this.id}.${Date.now().toString(36) + `_${++StaticCountWithinProcess}`}.${CLUSTER_WORKER_ID}${EXTNAME_UNCOMMITTED}`);
      debuglog(`[rotateFile] rotate to ${pathToRenameFile}`);
      try {
        fsAsync.rename(this.pathToCargoFile, pathToRenameFile);
      } catch (error) {
        err = error;
        debuglog(`[rotateFile] ABORT fail to rename file to ${pathToRenameFile}. error:`, err);
      }
      this._isFileRotating = false;
      return true;
    }

    // commit local rotated files to remote ClickHouse DB
    async commitToClickhouseDB() {
      var err, filenamList, filepath, j, len, rotationPrefix;
      if (this._isCommiting) {
        debuglog("[commitToClickhouseDB] SKIP is committing");
        return;
      }
      this._isCommiting = true; //lock on
      try {
        filenamList = fsAsync.readdir(this.pathToCargoFolder);
      } catch (error) {
        err = error;
        //debuglog "[commitToClickhouseDB > readdir] err:", err, ", filenamList:", filenamList
        debuglog("[commitToClickhouseDB > ls] FAILED error:", err);
        this._isCommiting = false; // lock release
        return;
      }
      if (!(Array.isArray(filenamList) && (filenamList.length > 0))) {
        this._isCommiting = false; // lock release
        return;
      }
      // filter out non-commits
      rotationPrefix = FILENAME_PREFIX + this.id + '.';
      filenamList = filenamList.filter(function(item) {
        return item.startsWith(rotationPrefix) && item.endsWith(EXTNAME_UNCOMMITTED);
      });
      if (!(filenamList.length > 0)) {
        this._isCommiting = false; // lock release
        return;
      }
      debuglog(`[commitToClickhouseDB] filenamList(${filenamList.length})`);
      filenamList = filenamList.map((item) => {
        return path.join(this.pathToCargoFolder, item);
      });
      for (j = 0, len = filenamList.length; j < len; j++) {
        filepath = filenamList[j];
        // submit 1 local uncommit to clickhouse
        debuglog(`[commitToClickhouseDB] submit:${filepath}`);
        try {
          await pipeline(fs.createReadStream(filepath), this.clichouseClient.query(this.statement, {
            format: 'JSONCompactEachRow'
          }));
          await fsAsync.unlink(filepath); // remove successfully commited local file
        } catch (error) {
          err = error;
          debuglog(`[commitToClickhouseDB] FAIL to commit:${filepath}, error:`, err);
        }
      }
      this._isCommiting = false; // lock release
    }

  };

  module.exports = Cargo;

}).call(this);
