// Generated by CoffeeScript 2.5.1
(function() {
  var CLUSTER_WORKER_ID, Cargo, DEFAULT_COMMIT_INTERVAL, DEFAULT_MAX_INSET_PARTS, EXTNAME_UNCOMMITTED, EventEmitter, FILENAME_PREFIX, MAX_COMMIT_PER_EXAM_ROUTINE, MIN_ROWS, MIN_TIME, NOOP, StaticCountWithinProcess, assert, cargoOptionToHttpOption, cluster, debuglog, fs, fsAsync, isThisLeader, os, path, promisify, qs, url;

  fs = require("fs");

  os = require("os");

  path = require("path");

  qs = require('querystring');

  cluster = require('cluster');

  assert = require("assert");

  EventEmitter = require('events');

  ({promisify} = require('util'));

  ({isThisLeader} = require("./leader_election"));

  ({cargoOptionToHttpOption} = require("./utils"));

  CLUSTER_WORKER_ID = cluster.isMaster ? "nocluster" : cluster.worker.id;

  debuglog = require("debug")(`chcargo:cargo@${CLUSTER_WORKER_ID}`);

  url = require('url');

  //pipeline = promisify(stream.pipeline)

  // to support node -v < 14
  fsAsync = {
    rename: promisify(fs.rename),
    unlink: promisify(fs.unlink),
    readdir: promisify(fs.readdir),
    appendFile: promisify(fs.appendFile),
    stat: promisify(fs.stat)
  };

  //debuglog "[static init] fsAsync:", fsAsync
  FILENAME_PREFIX = "cargo_";

  EXTNAME_UNCOMMITTED = ".uncommitted";

  NOOP = function() {};

  MAX_COMMIT_PER_EXAM_ROUTINE = 1;

  MIN_TIME = 1000;

  MIN_ROWS = 100;

  DEFAULT_COMMIT_INTERVAL = 5000;

  DEFAULT_MAX_INSET_PARTS = 100;

  StaticCountWithinProcess = 0;

  Cargo = class Cargo extends EventEmitter {
    toString() {
      return `[Cargo ${this.tableName}]`;
    }

    // @param SQLInsertString tableName
    // @param Object options:
    //                     .pathToCargoFolder
    //                     .maxTime
    //                     .maxRows
    //                     .commitInterval
    constructor(tableName, options = {}) {
      super();
      this.tableName = tableName;
      this.maxTime = parseInt(options.maxTime) || MIN_TIME;
      if (this.maxTime < MIN_TIME) {
        this.maxTime = MIN_TIME;
      }
      this.maxRows = parseInt(options.maxRows) || MIN_ROWS;
      if (this.maxRows < 1) {
        this.maxRows = MIN_ROWS;
      }
      this.commitInterval = parseInt(options.commitInterval) || DEFAULT_COMMIT_INTERVAL;
      if (this.commitInterval < this.maxTime) {
        this.commitInterval = DEFAULT_COMMIT_INTERVAL;
      }
      this.maxInsetParts = parseInt(options.maxInsetParts) || DEFAULT_MAX_INSET_PARTS;
      if (!(this.maxInsetParts > 0)) {
        this.maxInsetParts = DEFAULT_MAX_INSET_PARTS;
      }
      //@statement = "INSERT INTO #{@tableName} FORMAT JSONCompactEachRow\n"
      this.statement = `INSERT INTO ${this.tableName} FORMAT JSONCompactEachRow `;
      assert(options.pathToCargoFolder, "missing options.pathToCargoFolder");
      this.pathToCargoFolder = options.pathToCargoFolder;
      this.pathToCargoFile = path.join(this.pathToCargoFolder, FILENAME_PREFIX + this.tableName);
      this.httpPostOptions = cargoOptionToHttpOption(options, {
        path: '/?wait_end_of_query=1',
        method: 'POST'
      });
      this.vehicle = options.vehicle;
      debuglog(`[new Cargo] @tableName:${this.tableName}, @maxTime:${this.maxTime}, @maxRows:${this.maxRows}, @commitInterval:${this.commitInterval}, @pathToCargoFile:${this.pathToCargoFile}`);
      // verify cargo can write to the destination folder
      fs.access(this.pathToCargoFolder, fs.constants.W_OK, function(err) {
        if (err != null) {
          throw new Error(`Cargo not able to write to folder ${this.pathToCargoFolder}. Due to ${err}`);
        }
      });
      this.cachedRows = [];
      this.lastFlushAt = Date.now();
      this.lastCommitAt = Date.now();
      this.countRotation = 0;
      return;
    }

    // push row insert into memory cache
    push() {
      var arr, i, item, j, len;
      arr = Array.from(arguments);
      assert(arr.length > 0, "blank row can not be accepted.");
      for (i = j = 0, len = arr.length; j < len; i = ++j) {
        item = arr[i];
        if (item instanceof Date) {
          arr[i] = Math.round(item.getTime() / 1000);
        } else if (typeof b === "boolean") {
          arr[i] = Number(b);
        }
      }
      this.cachedRows.push(JSON.stringify(arr));
    }

    // flush memory cache to the disk file
    // @param forced Boolean, is force to flush file
    async flushToFile(forced) {
      var err, rowsToFlush;
      //debuglog("#{@} [flushToFile] @_isFlushing:", @_isFlushing)
      if (this._isFlushing) {
        return;
      }
      if (!(this.cachedRows.length > 0)) {
        //debuglog("#{@} [flushToFile] nothing to flush")
        this.lastFlushAt = Date.now();
        return;
      }
      if (!(forced || (this.cachedRows.length > this.maxRows) || (Date.now() > this.lastFlushAt + this.maxTime))) {
        return;
      }
      //debuglog("#{@} [flushToFile] SKIP threshold not reach")
      this._isFlushing = true;
      rowsToFlush = this.cachedRows;
      this.cachedRows = [];
      try {
        //debuglog("#{@} [flushToFile] -> #{rowsToFlush.length} rows")
        await fsAsync.appendFile(this.pathToCargoFile, rowsToFlush.join("\n") + "\n");
      } catch (error) {
        err = error;
        debuglog(`${this} [flushToFile] ${rowsToFlush.length} rows FAILED error:`, err);
        this.cachedRows = rowsToFlush.concat(this.cachedRows); // unshift data back
      }
      debuglog(`${this} [flushToFile] SUCCESS ${rowsToFlush.length} rows`);
      this.lastFlushAt = Date.now();
      this._isFlushing = false;
    }

    flushSync() {
      var rowsToFlush;
      if (!(this.cachedRows.length > 0)) {
        debuglog(`${this} [flushSync] nothing to flush`);
        return;
      }
      rowsToFlush = this.cachedRows;
      this.cachedRows = [];
      debuglog(`${this} [flushSync] ${rowsToFlush.length} rows`);
      fs.appendFileSync(this.pathToCargoFile, rowsToFlush.join("\n") + "\n");
    }

    uploadCargoFile(filepath) {
      var proc;
      debuglog(`[uploadCargoFile ${this.tableName}] filepath:`, filepath);
      proc = (resolve, reject) => {
        var err, req, srcStream;
        try {
          srcStream = fs.createReadStream(filepath);
        } catch (error) {
          err = error;
          reject(err);
          return;
        }
        req = this.vehicle.request(this.httpPostOptions, (res) => {
          if (!(res && res.statusCode === 200)) {
            reject(new Error(`ClickHouse server response statusCode:${res && res.statusCode}`));
            return;
          }
          //debuglog "[uploadCargoFile] res.headers:", res.headers
          resolve(res);
        });
        req.on('error', function(err) {
          debuglog("[uploadCargoFile : on err:]", err);
          reject(err);
        });
        req.on('timeout', function() {
          debuglog("[uploadCargoFile : on timeout]");
          req.destroy(new Error('request timeout'));
        });
        req.write(this.statement);
        srcStream.pipe(req);
      };
      return new Promise(proc);
    }

    // check if to commit disk file to clickhouse DB
    async exam() {
      var err, hasRotation;
      try {
        await this.flushToFile();
      } catch (error) {
        err = error;
        debuglog(`[exam ${this.tableName}] ABORT fail to flush. error:`, err);
        return;
      }
      if (!(Date.now() > this.lastCommitAt + this.commitInterval)) {
        return;
      }
      //debuglog "[exam #{@tableName}] SKIP tick not reach"
      if (!isThisLeader()) {
        debuglog(`[exam ${this.tableName}] CANCLE NOT leadWorkerId`);
        // non-leader skip 10 commit rounds
        this.lastCommitAt = Date.now() + this.commitInterval * 10;
        return;
      }
      try {
        //debuglog "[exam] LEAD COMMIT"
        hasRotation = (await this.rotateFile());
        //if hasRotation or @countRotation < 1
        // LAZY: commit only when: 1. has local rotated uncommits, or 2. first time exame to cargo to restore any previous local uncommits
        this.countRotation += Number(hasRotation);
        await this.commitToClickhouseDB();
        this.lastCommitAt = Date.now();
      } catch (error) {
        err = error;
        debuglog(`[exam ${this.tableName}] FAILED to commit. error:`, err);
      }
    }

    // prepar all uncommitted local files
    // @return Boolean, true if there are local uncommits exist
    async rotateFile() {
      var err, pathToRenameFile, stats;
      if (this._isFileRotating) {
        debuglog("[rotateFile] SKIP @_isFileRotating");
        return false;
      }
      this._isFileRotating = true; // lock on
      try {
        stats = (await fsAsync.stat(this.pathToCargoFile));
      } catch (error) {
        err = error;
        if (err.code !== 'ENOENT') {
          debuglog("[rotateFile] ABORT fail to stats file. error:", err);
        }
        //else
        //debuglog "[rotateFile] SKIP nothing to rotate"
        this._isFileRotating = false; // lock released
        return false;
      }
      //debuglog "[rotateFile > stat] err:", err,", stats:", stats
      if (!(stats && (stats.size > 0))) {
        debuglog("[rotateFile] SKIP empty file.");
        this._isFileRotating = false; // lock released
        return false;
      }
      // rotate disk file
      pathToRenameFile = path.join(this.pathToCargoFolder, `${FILENAME_PREFIX}${this.tableName}.${Date.now().toString(36) + `_${++StaticCountWithinProcess}`}.${CLUSTER_WORKER_ID}${EXTNAME_UNCOMMITTED}`);
      debuglog(`[rotateFile] rotate to ${pathToRenameFile}`);
      try {
        await fsAsync.rename(this.pathToCargoFile, pathToRenameFile);
      } catch (error) {
        err = error;
        debuglog(`[rotateFile] ABORT fail to rename file to ${pathToRenameFile}. error:`, err);
      }
      this._isFileRotating = false;
      return true;
    }

    // commit local rotated files to remote ClickHouse DB
    async commitToClickhouseDB() {
      var err, filenamList, filepath, j, len, res, rotationPrefix, splitMark;
      try {
        //debuglog "[commitToClickhouseDB]"
        //if @_isCommiting
        //debuglog "[commitToClickhouseDB] SKIP is committing"
        //return

        //@_isCommiting = true  #lock on
        filenamList = (await fsAsync.readdir(this.pathToCargoFolder));
      } catch (error) {
        err = error;
        //debuglog "[commitToClickhouseDB > readdir] err:", err, ", filenamList:", filenamList
        debuglog("[commitToClickhouseDB > ls] FAILED error:", err);
        return;
      }
      //debuglog "[commitToClickhouseDB > readdir] filenamList:", filenamList
      //@_isCommiting = false  # lock release
      if (!(Array.isArray(filenamList) && (filenamList.length > 0))) {
        debuglog("[commitToClickhouseDB] CANCLE empty filenamList");
        return;
      }
      // filter out non-commits
      //@_isCommiting = false  # lock release
      rotationPrefix = FILENAME_PREFIX + this.tableName + '.';
      filenamList = filenamList.filter(function(item) {
        return item.startsWith(rotationPrefix) && item.endsWith(EXTNAME_UNCOMMITTED);
      });
      if (!(filenamList.length > 0)) {
        debuglog("[commitToClickhouseDB > ls] CANCLE empty valid filenamList");
        return;
      }
      //@_isCommiting = false  # lock release
      debuglog(`[commitToClickhouseDB] filenamList(${filenamList.length})`);
      
      // sort filenamList from new to old
      splitMark = `${FILENAME_PREFIX}${this.tableName}.`;
      filenamList.sort(function(a, b) {
        var tsA, tsB;
        tsA = parseInt((a.split(splitMark) || [])[1] || 0, 36);
        tsB = parseInt((b.split(splitMark) || [])[1] || 0, 36);
        //debuglog "[commitToClickhouseDB] tsA:#{tsA} tsB:#{tsB}"
        return tsB - tsA;
      });
      debuglog(`[commitToClickhouseDB] AFTER SORT filenamList(${filenamList.length})`);
      
      // truncate filenamList if too long
      filenamList.length = Math.min(filenamList.length, this.maxInsetParts);
      debuglog(`[commitToClickhouseDB] AFTER SORT filenamList(${filenamList.length})`);
      
      // padding full file path
      filenamList = filenamList.map((item) => {
        return path.join(this.pathToCargoFolder, item);
      });
// submit each local uncommit sequentially
      for (j = 0, len = filenamList.length; j < len; j++) {
        filepath = filenamList[j];
        try {
          res = (await this.uploadCargoFile(filepath));
          debuglog(`[commitToClickhouseDB] res.headers: ${JSON.stringify(res.headers)}`);
          await fsAsync.unlink(filepath); // remove successfully commited local file
        } catch (error) {
          err = error;
          debuglog(`[commitToClickhouseDB] FAIL to commit:${filepath}, error:`, err);
          err.filepath = filepath;
          this.emit('error', err);
        }
      }
    }

  };

  //@_isCommiting = false  # lock release
  module.exports = Cargo;

}).call(this);
