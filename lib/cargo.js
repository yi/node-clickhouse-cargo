// Generated by CoffeeScript 2.5.1
(function() {
  var CLUSTER_WORKER_ID, Cargo, DEFAULT_COMMIT_INTERVAL, EXTNAME_UNCOMMITTED, FILENAME_PREFIX, MAX_COMMIT_PER_EXAM_ROUTINE, MIN_ROWS, MIN_TIME, MultiStream, NOOP, StaticCountWithinProcess, assert, cluster, crypto, debuglog, detectLeaderWorker, fs, os, path, pipeline, toSQLDateString;

  fs = require("fs");

  os = require("os");

  path = require("path");

  crypto = require('crypto');

  cluster = require('cluster');

  ({pipeline} = require('stream'));

  assert = require("assert");

  //CombinedStream = require('combined-stream')
  MultiStream = require('multistream');

  ({detectLeaderWorker} = require("./leader_election"));

  ({toSQLDateString} = require("./utils"));

  CLUSTER_WORKER_ID = cluster.isMaster ? "nocluster" : cluster.worker.id;

  debuglog = require("debug")(`chcargo:cargo@${CLUSTER_WORKER_ID}`);

  FILENAME_PREFIX = "cargo_";

  EXTNAME_UNCOMMITTED = ".uncommitted";

  NOOP = function() {};

  MAX_COMMIT_PER_EXAM_ROUTINE = 1;

  MIN_TIME = 1000;

  MIN_ROWS = 100;

  DEFAULT_COMMIT_INTERVAL = 5000;

  StaticCountWithinProcess = 0;

  Cargo = class Cargo {
    toString() {
      return `[Cargo ${this.id}]`;
    }

    // @param ClickHouse clichouseClient
    // @param SQLInsertString statement
    // @param Object options:
    //                     .pathToCargoFolder
    //                     .maxTime
    //                     .maxRows
    //                     .commitInterval
    constructor(clichouseClient, statement, options = {}) {
      this.clichouseClient = clichouseClient;
      this.statement = statement;
      this.maxTime = parseInt(options.maxTime) || MIN_TIME;
      if (this.maxTime < MIN_TIME) {
        this.maxTime = MIN_TIME;
      }
      this.maxRows = parseInt(options.maxRows) || MIN_ROWS;
      if (this.maxRows < 1) {
        this.maxRows = MIN_ROWS;
      }
      this.commitInterval = parseInt(options.commitInterval) || DEFAULT_COMMIT_INTERVAL;
      if (this.commitInterval < this.maxTime) {
        this.commitInterval = DEFAULT_COMMIT_INTERVAL;
      }
      this.id = crypto.createHash('md5').update(this.statement).digest("hex");
      this.count = 0;
      this.bulks = [];
      assert(options.pathToCargoFolder, "missing options.pathToCargoFolder");
      this.pathToCargoFolder = options.pathToCargoFolder;
      this.pathToCargoFile = path.join(this.pathToCargoFolder, FILENAME_PREFIX + this.id);
      debuglog(`[new Cargo] @statement:${this.statement}, @maxTime:${this.maxTime}, @maxRows:${this.maxRows}, @commitInterval:${this.commitInterval}, @pathToCargoFile:${this.pathToCargoFile}`);
      // verify cargo can write to the destination folder
      fs.access(this.pathToCargoFolder, fs.constants.W_OK, function(err) {
        if (err != null) {
          throw new Error(`Cargo not able to write to folder ${this.pathToCargoFolder}. Due to ${err}`);
        }
      });
      this.cachedRows = [];
      this.lastFlushAt = Date.now();
      this.lastCommitAt = Date.now();
      return;
    }

    // push row insert into memory cache
    push() {
      var arr, i, item, j, len;
      arr = Array.from(arguments);
      assert(arr.length > 0, "blank row can not be accepted.");
      for (i = j = 0, len = arr.length; j < len; i = ++j) {
        item = arr[i];
        if (item instanceof Date) {
          arr[i] = toSQLDateString(item);
        }
      }
      this.cachedRows.push(JSON.stringify(arr));
      if ((this.cachedRows.length > this.maxRows) || (Date.now() > this.lastFlushAt + this.maxRows)) {
        //debuglog "[push] row? #{(@cachedRows.length > @maxRows)}, time? #{(Date.now() > @lastFlushAt + @maxRows)} "
        this.flushToFile();
      }
    }

    // flush memory cache to the disk file
    // @callbak (err, isFlushing:Boolean)
    flushToFile(callbak = NOOP) {
      var rowsToFlush;
      //debuglog("#{@} [flushToFile] @_isFlushing:", @_isFlushing)
      if (this._isFlushing) {
        callbak(null, true);
        return;
      }
      if (!(this.cachedRows.length > 0)) {
        //debuglog("#{@} [flushToFile] nothing to flush")
        this.lastFlushAt = Date.now();
        callbak();
        return;
      }
      rowsToFlush = this.cachedRows;
      this.cachedRows = [];
      debuglog(`${this} [flushToFile] -> ${rowsToFlush.length} rows`);
      this._isFlushing = true;
      fs.appendFile(this.pathToCargoFile, rowsToFlush.join("\n") + "\n", (err) => {
        if (err != null) {
          debuglog(`${this} [flushToFile] FAILED error:`, err);
          this.cachedRows = rowsToFlush.concat(this.cachedRows); // unshift data back
        }
        debuglog(`${this} [flushToFile] SUCCESS ${rowsToFlush.length} rows`);
        this.lastFlushAt = Date.now();
        this._isFlushing = false;
        callbak(err);
      });
    }

    // check if to commit disk file to clickhouse DB
    exam() {
      //debuglog "[exam] go commit"
      this.flushToFile((err, isFlushing) => {
        if (err != null) {
          debuglog("[exam] ABORT fail to flush. error:", err);
          return;
        }
        if (isFlushing) {
          debuglog("[exam] ABORT isFlushing");
          return;
        }
        if (!(Date.now() > this.lastCommitAt + this.commitInterval)) {
          return;
        }
        //debuglog "[exam] SKIP tick not reach"
        fs.stat(this.pathToCargoFile, (err, stats) => {
          var pathToRenameFile;
          //debuglog "[exam > stat] err:", err,", stats:", stats
          if (err != null) {
            if (err.code === 'ENOENT') {
              debuglog("[exam] CANCLE nothing to commit");
              this.lastCommitAt = Date.now();
            } else {
              debuglog("[exam] ABORT fail to stats file. error:", err);
            }
            return;
          }
          if (!(stats && (stats.size > 0))) {
            debuglog("[exam] ABORT empty file.");
            return;
          }
          // rotate disk file
          pathToRenameFile = path.join(this.pathToCargoFolder, `${FILENAME_PREFIX}${this.id}.${Date.now().toString(36) + `_${++StaticCountWithinProcess}`}.${CLUSTER_WORKER_ID}${EXTNAME_UNCOMMITTED}`);
          debuglog(`[exam] rotate to ${pathToRenameFile}`);
          fs.rename(this.pathToCargoFile, pathToRenameFile, (err) => {
            if (err != null) {
              debuglog(`[exam] ABORT fail to rename file to ${pathToRenameFile}. error:`, err);
              return;
            }
            this.commitToClickhouseDB();
          });
        });
      });
    }

    // commit local rotated files to remote ClickHouse DB
    commitToClickhouseDB() {
      if (this._isCommiting) {
        debuglog("[commitToClickhouseDB] SKIP is committing");
        return;
      }
      // detect leader before every commit because worker might die
      detectLeaderWorker(this.id, (err, leadWorkerId) => {
        debuglog("[commitToClickhouseDB > detectLeaderWorker] err:", err, ", leadWorkerId:", leadWorkerId);
        if (err != null) {
          debuglog("[commitToClickhouseDB > detectLeaderWorker] FAILED error:", err);
          return;
        }
        // only one process can commit
        if (leadWorkerId !== CLUSTER_WORKER_ID) {
          debuglog(`[commitToClickhouseDB] CANCLE leadWorkerId:${leadWorkerId} unmatch CLUSTER_WORKER_ID:${CLUSTER_WORKER_ID}`);
          return;
        }
        fs.readdir(this.pathToCargoFolder, (err, filenamList) => {
          var combinedStream, dbStream, rotationPrefix;
          //debuglog "[commitToClickhouseDB > readdir] err:", err, ", filenamList:", filenamList
          if (err != null) {
            debuglog("[commitToClickhouseDB > ls] FAILED error:", err);
            return;
          }
          if (!Array.isArray(filenamList)) {
            return;
          }
          rotationPrefix = FILENAME_PREFIX + this.id + '.';
          filenamList = filenamList.filter(function(item) {
            return item.startsWith(rotationPrefix) && item.endsWith(EXTNAME_UNCOMMITTED);
          });
          if (!(filenamList.length > 0)) {
            return;
          }
          debuglog(`[commitToClickhouseDB] filenamList(${filenamList.length})`);
          filenamList = filenamList.map((item) => {
            return path.join(this.pathToCargoFolder, item);
          });
          this._isCommiting = true; //lock
          dbStream = this.clichouseClient.query(this.statement, {
            format: 'JSONCompactEachRow'
          });
          dbStream.on('error', (err) => {
            debuglog(`${this} [commitToClickhouseDB > DB write] FAILED error:`, err);
            this._isCommiting = false;
          });
          dbStream.on('finish', () => {
            var filepath, j, len;
            debuglog(`${this} [commitToClickhouseDB] success dbStream:finish`);
            this._isCommiting = false;
            for (j = 0, len = filenamList.length; j < len; j++) {
              filepath = filenamList[j];
              fs.unlink(filepath, NOOP); // remove the physical file
            }
          });
          combinedStream = new MultiStream(filenamList.map(function(filepath) {
            return fs.createReadStream(filepath);
          }));
          //console.dir combinedStream , depth:10
          combinedStream.pipe(dbStream);
        });
      });
    }

  };

  module.exports = Cargo;

}).call(this);
