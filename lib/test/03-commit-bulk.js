// Generated by CoffeeScript 2.5.1
(function() {
  var NUM_OF_LINE, STATEMENT_CREATE_TABLE, STATEMENT_DROP_TABLE, STATEMENT_INSERT, STATEMENT_SELECT, TABLE_NAME, assert, createCargo, debuglog, fs, getClickHouseClient, isInited;

  ({createCargo, isInited, getClickHouseClient} = require("../"));

  debuglog = require("debug")("chcargo:test:03");

  assert = require("assert");

  fs = require("fs");

  TABLE_NAME = "cargo_test.unittest03";

  STATEMENT_CREATE_TABLE = `CREATE TABLE IF NOT EXISTS ${TABLE_NAME}
(
  \`time\` DateTime ,
  \`step\`  UInt32,
  \`pos_id\` String DEFAULT ''
)
ENGINE = Memory()`;

  STATEMENT_CREATE_TABLE = STATEMENT_CREATE_TABLE.replace(/\n|\r/g, ' ');

  STATEMENT_INSERT = `INSERT INTO ${TABLE_NAME}`;

  STATEMENT_DROP_TABLE = `DROP TABLE ${TABLE_NAME}`;

  //STATEMENT_SELECT = "SELECT * FROM #{TABLE_NAME} LIMIT 10000000"
  STATEMENT_SELECT = `SELECT * FROM ${TABLE_NAME} LIMIT 10000000 FORMAT JSONCompactEachRow `;

  NUM_OF_LINE = 27891; // NOTE: bulk flushs every 100 lines

  //NUM_OF_LINE = 9  # NOTE: bulk flushs every 100 lines
  describe("commit bulk", function() {
    var theBulk, theCargo, theFilepath;
    this.timeout(60000);
    theCargo = null;
    theBulk = null;
    theFilepath = null;
    before(function(done) {
      theCargo = createCargo(STATEMENT_INSERT);
      theBulk = theCargo.curBulk;
      theFilepath = theBulk.pathToFile;
      getClickHouseClient().query(STATEMENT_CREATE_TABLE, done);
    });
    after(function(done) {
      debuglog("[after] query:", STATEMENT_DROP_TABLE);
      getClickHouseClient().query(STATEMENT_DROP_TABLE, function(err) {
        done(err);
        if (err == null) {
          process.exit();
        }
      });
    });
    it("push to cargo", function(done) {
      var i, j, ref;
      for (i = j = 0, ref = NUM_OF_LINE; (0 <= ref ? j < ref : j > ref); i = 0 <= ref ? ++j : --j) {
        theCargo.push(new Date(), i, "string");
      }
      setTimeout(done, 10000); // wait file stream flush
    });
    it("bulk should committed", function(done) {
      var curBulk;
      assert(theBulk.isCommitted(), "the bulk should committed");
      curBulk = theCargo.curBulk;
      assert(curBulk !== theBulk, "previouse bulk should not be the current bulk");
      assert(theCargo.getRetiredBulks().length === 0, "committed bulks should be cleared");
      assert(!fs.existsSync(theFilepath), "local file must be cleared");
      done();
    });
    it("records should be written into remote ClickHouse server", function(done) {
      var rows, stream;
      rows = [];
      debuglog("[read db] select:", STATEMENT_SELECT);
      stream = getClickHouseClient().query(STATEMENT_SELECT, {
        format: "JSONCompactEachRow"
      }, function(err, result) {
        var i, j, len, row;
        if (err != null) {
          done(err);
          return;
        }
        result = result.replace(/\n/g, ",").trim().replace(/,$/, '');
        result = `[ ${result} ]`;
        //console.dir result
        result = JSON.parse(result);
        debuglog("[read db] result:", result.length);
        //console.dir result, depth:10
        assert(result.length === NUM_OF_LINE, `unmatching row length local:${NUM_OF_LINE}, remote:${result.length}`);
        result.sort(function(a, b) {
          return a[1] - b[1];
        });
        for (i = j = 0, len = result.length; j < len; i = ++j) {
          row = result[i];
          assert(row[1] === i, "unmatching field 1 ");
          assert(row[2] === "string", "unmatching field 2 ");
        }
        done();
      });
    });
  });

}).call(this);
