// Generated by CoffeeScript 2.5.1
(function() {
  var Bulk, NUM_OF_LINES_TO_CORK, StaticCountWithProcess, assert, cluster, debuglog, fs, path, toSQLDateString;

  cluster = require('cluster');

  path = require("path");

  fs = require("fs");

  assert = require("assert");

  debuglog = require("debug")("chcargo:bulk");

  StaticCountWithProcess = 0;

  // cork stream write
  NUM_OF_LINES_TO_CORK = 100;

  toSQLDateString = function(date) {
    return date.getUTCFullYear() + '-' + ('00' + (date.getUTCMonth() + 1)).slice(-2) + '-' + ('00' + date.getUTCDate()).slice(-2) + ' ' + ('00' + date.getUTCHours()).slice(-2) + ':' + ('00' + date.getUTCMinutes()).slice(-2) + ':' + ('00' + date.getUTCSeconds()).slice(-2);
  };

  Bulk = class Bulk {
    toString() {
      return `[Bulk ${this.id}@${this.pathToFile}]`;
    }

    constructor(workingPath) {
      this.id = Date.now().toString(36) + `_${++StaticCountWithProcess}`;
      if (cluster.isWorker) {
        // when launch as a worker by pm2
        this.id += `_${cluster.worker.id}`;
      }
      this.count = 0;
      this.pathToFile = path.join(workingPath, `bulk-${this.id}`);
      this.outputStream = fs.createWriteStream(this.pathToFile, {
        flags: 'a'
      });
      // make sure writableStream is working
      this.outputStream.write("");
      this._committed = false;
      this._committing = false;
      return;
    }

    push(arr) {
      var i, item, j, len, line;
      if (!(Array.isArray(arr) && (arr.length > 0))) {
        debuglog(`${this} [push] empty arr`);
        return;
      }
      for (i = j = 0, len = arr.length; j < len; i = ++j) {
        item = arr[i];
        if (item instanceof Date) {
          item[i] = toSQLDateString(item);
        }
      }
      line = JSON.stringify(arr);
      if (this.count % NUM_OF_LINES_TO_CORK === 0) {
        //debuglog "#{@} [push] line:", line

        // the primary intent of writable.cork() is to accommodate a situation in which several small chunks are written to the stream in rapid succession.
        this.outputStream.cork();
      }
      this.outputStream.write((this.count > 0 ? "\n" : "") + line, 'utf8');
      ++this.count;
      if (this.count % NUM_OF_LINES_TO_CORK === 0) {
        process.nextTick(() => {
          return this.outputStream.uncork();
        });
      }
    }

    // set the expiration of this bulk
    expire(ttl) {
      debuglog(`${this} [expire] ttl:${ttl}`);
      ttl = parseInt(ttl) || 0;
      if (ttl < 1000) {
        ttl = 1000;
      }
      this.expireAt = Date.now() + ttl;
    }

    commit(clichouseClient, statement) {
      var theOutputStream;
      if (this._committing) {
        debuglog(`${this} [commit] IGNORE is _committing`);
        return;
      }
      assert(statement, "missing insert statment");
      this._committing = true; //lock
      debuglog(`${this} [commit] go committing`);
      theOutputStream = this.outputStream;
      theOutputStream.end((err) => {
        var dbStream, readableStream;
        if (err != null) {
          debuglog(`${this} [commit] FAIL to end stream. error:`, err);
          this._committing = false; //unlock
          return;
        }
        dbStream = clichouseClient.query(statement, (err) => {
          if (err != null) {
            debuglog(`${this} [commit] FAIL db query. error:`, err);
            this._committing = false; //unlock
            return;
          }
          this._committing = false;
          this._committed = true;
          theOutputStream.destroy();
          readableStream.destroy();
          fs.unlink(this.pathToFile); // remove the physical file
          debuglog(`${this} [commit] success`);
        });
        readableStream = fs.createReadStream(this.pathToFile);
        readableStream.pipe(dbStream);
      });
    }

    isExpired() {
      return (parseInt(this.expireAt) || 0) <= Date.now();
    }

    isEmpty() {
      return this.count === 0;
    }

    isCommitted() {
      return this._committed === true;
    }

  };

  module.exports = Bulk;

}).call(this);
